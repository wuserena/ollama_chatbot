{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7ee5db2-722b-4593-9702-28194ac88b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f069049055ea4ae4a2348a75ef2ab8b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Image(value=b'', format='jpeg', height='480', width='640')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09985534c6004e45bc3b12f4cdb161dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Stop Camera', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1743448460.528862    1587 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n"
     ]
    }
   ],
   "source": [
    "#2/20 final\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from threading import Thread\n",
    "from MangDang.mini_pupper.ESP32Interface import ESP32Interface\n",
    "from MangDang.mini_pupper.Config import PWMParams\n",
    "\n",
    "esp32 = ESP32Interface()\n",
    "esp32.connect()\n",
    "\n",
    "\n",
    "positions = [512] * 12\n",
    "servo_yaw = 1\n",
    "servo_pitch = 2\n",
    "esp32.servos_set_position(positions)\n",
    "\n",
    "# range\n",
    "yaw_min, yaw_max = 450, 600   #left and right\n",
    "pitch_min, pitch_max = 450, 600\n",
    "\n",
    "\n",
    "mp_face_detection = mp.solutions.face_detection\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# axis of center\n",
    "frame_width = int(cap.get(3))\n",
    "frame_height = int(cap.get(4))\n",
    "screen_center_x = frame_width // 2\n",
    "screen_center_y = frame_height // 2\n",
    "\n",
    "\n",
    "tracker = cv2.TrackerKCF_create()\n",
    "tracking = False\n",
    "\n",
    "\n",
    "yaw_sensitivity = 0.05\n",
    "pitch_sensitivity = 0.05\n",
    "max_adjust = 30\n",
    "\n",
    "image_widget = widgets.Image(format='jpeg', width=640, height=480)\n",
    "stop_button = widgets.Button(description=\"Stop Camera\")\n",
    "\n",
    "running = True\n",
    "\n",
    "def update_camera():\n",
    "    global running, tracking, tracker, positions\n",
    "\n",
    "    with mp_face_detection.FaceDetection(model_selection=0, min_detection_confidence=0.5) as face_detection:\n",
    "        while running:\n",
    "            success, image = cap.read()\n",
    "            if not success:\n",
    "                continue\n",
    "\n",
    "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "            if not tracking:\n",
    "                results = face_detection.process(image_rgb)\n",
    "\n",
    "                if results.detections:\n",
    "                    for detection in results.detections:\n",
    "                        bboxC = detection.location_data.relative_bounding_box\n",
    "                        h_img, w_img, _ = image.shape\n",
    "                        x = int(bboxC.xmin * w_img)\n",
    "                        y = int(bboxC.ymin * h_img)\n",
    "                        w = int(bboxC.width * w_img)\n",
    "                        h = int(bboxC.height * h_img)\n",
    "\n",
    "                        if x < 0 or y < 0 or w <= 0 or h <= 0:\n",
    "                            continue\n",
    "\n",
    "                        tracker = cv2.TrackerKCF_create()\n",
    "                        tracker.init(image, (x, y, w, h))\n",
    "                        tracking = True\n",
    "                        break\n",
    "\n",
    "            else:\n",
    "                success, bbox = tracker.update(image)\n",
    "                if success:\n",
    "                    x, y, w, h = [int(v) for v in bbox]\n",
    "                    cx, cy = x + w // 2, y + h // 2\n",
    "\n",
    "\n",
    "                    error_x = (cx - screen_center_x) / frame_width\n",
    "                    error_y = (cy - screen_center_y) / frame_height\n",
    "\n",
    "\n",
    "                    adjust_factor_x = min(1.0, abs(error_x) * 5)\n",
    "                    adjust_factor_y = min(1.0, abs(error_y) * 5)\n",
    "\n",
    "\n",
    "                    if abs(error_x) > yaw_sensitivity:\n",
    "                        yaw_adjust = int(positions[servo_yaw - 1] + max_adjust * error_x * adjust_factor_x)\n",
    "                        positions[servo_yaw - 1] = max(yaw_min, min(yaw_max, yaw_adjust))\n",
    "                    \n",
    "                    if abs(error_y) > pitch_sensitivity:\n",
    "                        pitch_adjust = int(positions[servo_pitch - 1] + max_adjust * error_y * adjust_factor_y)\n",
    "                        positions[servo_pitch - 1] = max(pitch_min, min(pitch_max, pitch_adjust))\n",
    "                    \n",
    "\n",
    "                    #torque = [1] * 12\n",
    "                    esp32.servos_set_position(positions)\n",
    "\n",
    "\n",
    "                    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 3)\n",
    "                    cv2.circle(image, (cx, cy), 5, (0, 0, 255), -1)\n",
    "                    cv2.putText(image, f\"C: {cx},{cy}\", (cx - 40, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "                else:\n",
    "                    tracking = False\n",
    "\n",
    "\n",
    "            _, frame_jpeg = cv2.imencode('.jpeg', image)\n",
    "            image_widget.value = frame_jpeg.tobytes()\n",
    "\n",
    "            time.sleep(0.05)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "\n",
    "def stop_camera(button):\n",
    "    global running\n",
    "    running = False\n",
    "    stop_button.disabled = True\n",
    "\n",
    "stop_button.on_click(stop_camera)\n",
    "\n",
    "display(image_widget, stop_button)\n",
    "\n",
    "thread = Thread(target=update_camera)\n",
    "thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ee287a1-1ba3-4531-98ec-db822ece3f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MangDang.mini_pupper.ESP32Interface import ESP32Interface\n",
    "import time\n",
    "\n",
    "# start position (neutral position)\n",
    "positions = [512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512]\n",
    "# which servos to move: count servos from 1 to 12\n",
    "servos = 1\n",
    "# maximum deviation from neutral position\n",
    "max_delta = 50\n",
    "esp32 = ESP32Interface()\n",
    "\n",
    "delta = 10\n",
    "upper_max = min(512 + max_delta, 1023)\n",
    "lower_min = max(512 - max_delta, 0)\n",
    "positions[servos - 1] += delta\n",
    "#esp32.servos_set_position(positions)\n",
    "#torque = [1] * 12\n",
    "esp32.servos_set_position(positions)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8a7ed1-492e-4fae-aa96-7f8c8f2f19c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512, 513, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from MangDang.mini_pupper.ESP32Interface import ESP32Interface\n",
    "import time\n",
    "\n",
    "esp32 = ESP32Interface()\n",
    "\n",
    "print(esp32.servos_get_position())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
